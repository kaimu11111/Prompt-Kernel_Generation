{
  "error_type": "CompilationError",
  "message": "Using /home/wan00559/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\nThe input conditions for extension module matmul_optimized have changed. Bumping to version 6 and re-building as matmul_optimized_v6...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/build.ninja...\n/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nBuilding extension module matmul_optimized_v6...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=matmul_optimized_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/main.cpp -o main.o \n[2/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=matmul_optimized_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -use_fast_math -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu -o cuda.cuda.o \nFAILED: cuda.cuda.o \n/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=matmul_optimized_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -use_fast_math -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu -o cuda.cuda.o \nIn file included from /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu:8:\n/usr/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n   54 | #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n      |  ^~~~~~~\nIn file included from /home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu:8:\n/usr/include/math_functions.h:54:2: warning: #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\" [-Wcpp]\n   54 | #warning \"math_functions.h is an internal header file and must not be used directly.  This file will be removed in a future CUDA release.  Please use cuda_runtime_api.h or cuda_runtime.h instead.\"\n      |  ^~~~~~~\n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu(49): error: identifier \"__fma__\" is undefined\n\n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu(52): error: identifier \"__fma__\" is undefined\n\n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu(55): error: identifier \"__fma__\" is undefined\n\n/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu(58): error: identifier \"__fma__\" is undefined\n\n4 errors detected in the compilation of \"/home/wan00559/.cache/torch_extensions/py311_cu126/matmul_optimized/cuda.cu\".\nninja: build stopped: subcommand failed.\nError building extension 'matmul_optimized_v6'"
}
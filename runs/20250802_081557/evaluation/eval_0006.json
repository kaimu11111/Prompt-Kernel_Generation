{
  "error_type": "CompilationError",
  "message": "Using /home/wan00559/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\nThe input conditions for extension module conv_relu_add_bias_unrolled have changed. Bumping to version 2 and re-building as conv_relu_add_bias_unrolled_v2...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/build.ninja...\n/home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nBuilding extension module conv_relu_add_bias_unrolled_v2...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=conv_relu_add_bias_unrolled_v2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/main.cpp -o main.o \n[2/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=conv_relu_add_bias_unrolled_v2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu -o cuda.cuda.o \nFAILED: cuda.cuda.o \n/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=conv_relu_add_bias_unrolled_v2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include -isystem /home/wan00559/miniconda3/envs/maxk/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/wan00559/miniconda3/envs/maxk/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu -o cuda.cuda.o \n/home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu(49): error: declaration is incompatible with previous \"shared\"\n(49): here\n          detected during instantiation of \"void conv_relu_add_bias_unrolled_kernel(const T *, const T *, const T *, T *, int, int, int, int, int, int, int, int) [with T=float]\" \n(128): here\n\n/home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu(49): warning #20042-D: a host variable(\"shared\") redeclared with __shared__\n          detected during instantiation of \"void conv_relu_add_bias_unrolled_kernel(const T *, const T *, const T *, T *, int, int, int, int, int, int, int, int) [with T=float]\" \n(128): here\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n          detected during instantiation of \"void conv_relu_add_bias_unrolled_kernel(const T *, const T *, const T *, T *, int, int, int, int, int, int, int, int) [with T=float]\" \n/home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu(128): here\n\n1 error detected in the compilation of \"/home/wan00559/.cache/torch_extensions/py311_cu126/conv_relu_add_bias_unrolled/cuda.cu\".\nninja: build stopped: subcommand failed.\nError building extension 'conv_relu_add_bias_unrolled_v2'"
}